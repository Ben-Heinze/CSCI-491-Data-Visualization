{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3- Scatterplot, dimension reduction and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are strongly encouraged to work on this assignment with one or two partners. Please ensure only one submission per group: upload the PDF report to Gradescope and the code (or Jupyter notebook) to D2L. The dataset CSV file for Assignment 3 can be found on D2L."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is based on real-world data, not synthetic, so don't anticipate very clear-cut clusters or trends. There's no single correct answer to any question. Aim to thoroughly explain your analysis and the reasoning behind your choices as effectively as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "In this assignement, we focus on ```heart failure clinical records dataset```,from [UCI Machine Learning repository](https://archive-beta.ics.uci.edu/). It includes the medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features  and you can access more information about this dataset [here](https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart=pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "# excludes binary vars\n",
    "numerical = heart.drop(columns=['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT'])\n",
    "# excludes numerical vars\n",
    "categorical = heart.drop(columns=['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1- Scatterplots (50 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) 10 points- (EP)\n",
    "Get to know the dataset by generating summary statistics for the numerical variables, such as mean, median, and standard deviation. Address any missing values and outliers. Which variables do you think might be crucial in determining patient survival? Which variables seem to be most closely correlated.\n",
    "\n",
    "[Summary Statistics Pandas Resource](https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Values for Numerical Data:\n",
      "age                             60.833893\n",
      "creatinine_phosphokinase       581.839465\n",
      "ejection_fraction               38.083612\n",
      "platelets                   263358.029264\n",
      "serum_creatinine                 1.393880\n",
      "serum_sodium                   136.625418\n",
      "time                           130.260870\n",
      "dtype: float64\n",
      "\n",
      "Median Values for Numerical Data:\n",
      "age                             60.0\n",
      "creatinine_phosphokinase       250.0\n",
      "ejection_fraction               38.0\n",
      "platelets                   262000.0\n",
      "serum_creatinine                 1.1\n",
      "serum_sodium                   137.0\n",
      "time                           115.0\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations for Numerical Data:\n",
      "age                            11.894809\n",
      "creatinine_phosphokinase      970.287881\n",
      "ejection_fraction              11.834841\n",
      "platelets                   97804.236869\n",
      "serum_creatinine                1.034510\n",
      "serum_sodium                    4.412477\n",
      "time                           77.614208\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean, median, standard deviation\n",
    "print(\"Mean Values for Numerical Data:\\n\" + str(numerical.mean()) + \"\\n\")\n",
    "print(\"Median Values for Numerical Data:\\n\" + str(numerical.median()) + \"\\n\")\n",
    "print(\"Standard Deviations for Numerical Data:\\n\" + str(numerical.std()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         0\n",
       "creatinine_phosphokinase    0\n",
       "ejection_fraction           0\n",
       "platelets                   0\n",
       "serum_creatinine            0\n",
       "serum_sodium                0\n",
       "time                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "numerical.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1acb_row0_col0, #T_b1acb_row1_col1, #T_b1acb_row2_col2, #T_b1acb_row3_col3, #T_b1acb_row4_col4, #T_b1acb_row5_col5, #T_b1acb_row6_col6 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row0_col1, #T_b1acb_row1_col0 {\n",
       "  background-color: #7b3488;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row0_col2, #T_b1acb_row1_col5, #T_b1acb_row2_col0, #T_b1acb_row3_col5, #T_b1acb_row5_col1, #T_b1acb_row5_col3 {\n",
       "  background-color: #a681b6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row0_col3, #T_b1acb_row3_col0 {\n",
       "  background-color: #834492;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row0_col4, #T_b1acb_row4_col0 {\n",
       "  background-color: #c7abd2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1acb_row0_col5, #T_b1acb_row1_col2, #T_b1acb_row2_col1, #T_b1acb_row5_col0 {\n",
       "  background-color: #864a95;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row0_col6, #T_b1acb_row6_col0 {\n",
       "  background-color: #40004b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row1_col3, #T_b1acb_row3_col1 {\n",
       "  background-color: #9970ab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row1_col4, #T_b1acb_row4_col1 {\n",
       "  background-color: #8e5a9e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row1_col6, #T_b1acb_row2_col4, #T_b1acb_row4_col2, #T_b1acb_row6_col1 {\n",
       "  background-color: #8f5da0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row2_col3, #T_b1acb_row3_col2 {\n",
       "  background-color: #a985b9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row2_col5, #T_b1acb_row5_col2 {\n",
       "  background-color: #cbb1d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1acb_row2_col6, #T_b1acb_row6_col2 {\n",
       "  background-color: #9f78b1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row3_col4, #T_b1acb_row4_col3 {\n",
       "  background-color: #874c97;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row3_col6, #T_b1acb_row6_col3 {\n",
       "  background-color: #966ba8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row4_col5, #T_b1acb_row5_col4 {\n",
       "  background-color: #4f0c5a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row4_col6, #T_b1acb_row6_col4 {\n",
       "  background-color: #60196c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1acb_row5_col6, #T_b1acb_row6_col5 {\n",
       "  background-color: #b08dbf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1acb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b1acb_level0_col0\" class=\"col_heading level0 col0\" >age</th>\n",
       "      <th id=\"T_b1acb_level0_col1\" class=\"col_heading level0 col1\" >creatinine_phosphokinase</th>\n",
       "      <th id=\"T_b1acb_level0_col2\" class=\"col_heading level0 col2\" >ejection_fraction</th>\n",
       "      <th id=\"T_b1acb_level0_col3\" class=\"col_heading level0 col3\" >platelets</th>\n",
       "      <th id=\"T_b1acb_level0_col4\" class=\"col_heading level0 col4\" >serum_creatinine</th>\n",
       "      <th id=\"T_b1acb_level0_col5\" class=\"col_heading level0 col5\" >serum_sodium</th>\n",
       "      <th id=\"T_b1acb_level0_col6\" class=\"col_heading level0 col6\" >time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b1acb_level0_row0\" class=\"row_heading level0 row0\" >age</th>\n",
       "      <td id=\"T_b1acb_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_b1acb_row0_col1\" class=\"data row0 col1\" >-0.081584</td>\n",
       "      <td id=\"T_b1acb_row0_col2\" class=\"data row0 col2\" >0.060098</td>\n",
       "      <td id=\"T_b1acb_row0_col3\" class=\"data row0 col3\" >-0.052354</td>\n",
       "      <td id=\"T_b1acb_row0_col4\" class=\"data row0 col4\" >0.159187</td>\n",
       "      <td id=\"T_b1acb_row0_col5\" class=\"data row0 col5\" >-0.045966</td>\n",
       "      <td id=\"T_b1acb_row0_col6\" class=\"data row0 col6\" >-0.224068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1acb_level0_row1\" class=\"row_heading level0 row1\" >creatinine_phosphokinase</th>\n",
       "      <td id=\"T_b1acb_row1_col0\" class=\"data row1 col0\" >-0.081584</td>\n",
       "      <td id=\"T_b1acb_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_b1acb_row1_col2\" class=\"data row1 col2\" >-0.044080</td>\n",
       "      <td id=\"T_b1acb_row1_col3\" class=\"data row1 col3\" >0.024463</td>\n",
       "      <td id=\"T_b1acb_row1_col4\" class=\"data row1 col4\" >-0.016408</td>\n",
       "      <td id=\"T_b1acb_row1_col5\" class=\"data row1 col5\" >0.059550</td>\n",
       "      <td id=\"T_b1acb_row1_col6\" class=\"data row1 col6\" >-0.009346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1acb_level0_row2\" class=\"row_heading level0 row2\" >ejection_fraction</th>\n",
       "      <td id=\"T_b1acb_row2_col0\" class=\"data row2 col0\" >0.060098</td>\n",
       "      <td id=\"T_b1acb_row2_col1\" class=\"data row2 col1\" >-0.044080</td>\n",
       "      <td id=\"T_b1acb_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_b1acb_row2_col3\" class=\"data row2 col3\" >0.072177</td>\n",
       "      <td id=\"T_b1acb_row2_col4\" class=\"data row2 col4\" >-0.011302</td>\n",
       "      <td id=\"T_b1acb_row2_col5\" class=\"data row2 col5\" >0.175902</td>\n",
       "      <td id=\"T_b1acb_row2_col6\" class=\"data row2 col6\" >0.041729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1acb_level0_row3\" class=\"row_heading level0 row3\" >platelets</th>\n",
       "      <td id=\"T_b1acb_row3_col0\" class=\"data row3 col0\" >-0.052354</td>\n",
       "      <td id=\"T_b1acb_row3_col1\" class=\"data row3 col1\" >0.024463</td>\n",
       "      <td id=\"T_b1acb_row3_col2\" class=\"data row3 col2\" >0.072177</td>\n",
       "      <td id=\"T_b1acb_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_b1acb_row3_col4\" class=\"data row3 col4\" >-0.041198</td>\n",
       "      <td id=\"T_b1acb_row3_col5\" class=\"data row3 col5\" >0.062125</td>\n",
       "      <td id=\"T_b1acb_row3_col6\" class=\"data row3 col6\" >0.010514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1acb_level0_row4\" class=\"row_heading level0 row4\" >serum_creatinine</th>\n",
       "      <td id=\"T_b1acb_row4_col0\" class=\"data row4 col0\" >0.159187</td>\n",
       "      <td id=\"T_b1acb_row4_col1\" class=\"data row4 col1\" >-0.016408</td>\n",
       "      <td id=\"T_b1acb_row4_col2\" class=\"data row4 col2\" >-0.011302</td>\n",
       "      <td id=\"T_b1acb_row4_col3\" class=\"data row4 col3\" >-0.041198</td>\n",
       "      <td id=\"T_b1acb_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_b1acb_row4_col5\" class=\"data row4 col5\" >-0.189095</td>\n",
       "      <td id=\"T_b1acb_row4_col6\" class=\"data row4 col6\" >-0.149315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1acb_level0_row5\" class=\"row_heading level0 row5\" >serum_sodium</th>\n",
       "      <td id=\"T_b1acb_row5_col0\" class=\"data row5 col0\" >-0.045966</td>\n",
       "      <td id=\"T_b1acb_row5_col1\" class=\"data row5 col1\" >0.059550</td>\n",
       "      <td id=\"T_b1acb_row5_col2\" class=\"data row5 col2\" >0.175902</td>\n",
       "      <td id=\"T_b1acb_row5_col3\" class=\"data row5 col3\" >0.062125</td>\n",
       "      <td id=\"T_b1acb_row5_col4\" class=\"data row5 col4\" >-0.189095</td>\n",
       "      <td id=\"T_b1acb_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_b1acb_row5_col6\" class=\"data row5 col6\" >0.087640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1acb_level0_row6\" class=\"row_heading level0 row6\" >time</th>\n",
       "      <td id=\"T_b1acb_row6_col0\" class=\"data row6 col0\" >-0.224068</td>\n",
       "      <td id=\"T_b1acb_row6_col1\" class=\"data row6 col1\" >-0.009346</td>\n",
       "      <td id=\"T_b1acb_row6_col2\" class=\"data row6 col2\" >0.041729</td>\n",
       "      <td id=\"T_b1acb_row6_col3\" class=\"data row6 col3\" >0.010514</td>\n",
       "      <td id=\"T_b1acb_row6_col4\" class=\"data row6 col4\" >-0.149315</td>\n",
       "      <td id=\"T_b1acb_row6_col5\" class=\"data row6 col5\" >0.087640</td>\n",
       "      <td id=\"T_b1acb_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x18b37252250>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables most correlated\n",
    "numerical.corr().style.background_gradient(cmap='PRGn', axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing values: No missing values\n",
    "- Outliers: \n",
    "- Crucial Survival Variables: Some of the variables most crucial to determining patient survival might include age, ejection fraction, whether the patient has hypertension or diabetes, as well as whether a patient smokes or not.\n",
    "- Variables most correlated: Based on the correlation matrix generated above, it appears the variables that have the strongest correlation would be time and age, serum_sodium and serum_creatinine, and time and serum_creatinine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) 20 points (BH)\n",
    "Create pair plot and correlation matrix among the different numerical variables. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair plot\n",
    "sns.pairplot(numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pair Plot Findings:__\n",
    " - Ages 40-100 appear to to evenly spread across each numerical category\n",
    " - Low serum_creatinine is correlated with medium-to-high serum sodiums\n",
    " - Low serum creatinine seems strongly correlated with much lower creatinine phosphokinase\n",
    " - Most ages have less than 1000 KCP mcg/L (creatinine phosphokinase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "correlationMatrix = numerical.corr()\n",
    "correlationMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Correlation Matrix Findings:__\n",
    "- The range of corrleation is [-.224, .176] which mostly hovers around 0. This means most categories have little correlation.\n",
    "- The highest positive correlation is between ejectional fraction and serum sodium.\n",
    "- The highest negative correlation is between age and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) 20 points (EP)\n",
    "Explore different pairs of variables. Create two separate scatterplots and color points based on Death variable, `DEATH_EVENT` or other categorical variables. Do you see any ditinctive groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2- Dimension Reduction (50 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) 15 points (BH)\n",
    "Perform PCA on the **standardized numerical variables**. Plot cumulative explained variance. \n",
    "How many principal components are needed to capture 80% of the variance? Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnTitles = ['age', 'creatine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']\n",
    "\n",
    "#Standardize numerical set\n",
    "scaler = StandardScaler()\n",
    "numericalRescale = scaler.fit_transform(numerical)\n",
    "numericalRescale = pd.DataFrame(numericalRescale)\n",
    "numericalRescale.columns = columnTitles\n",
    "\n",
    "\n",
    "#PCA on standardized Numerial Set (uses 7 components to see which ones are most useful)\n",
    "numericalPCA = PCA(n_components=7)\n",
    "pcaTransformedDataset = numericalPCA.fit_transform(numericalRescale) #gives me access to .components_ and explained_variance_ratio_\n",
    "\n",
    "#Prints PCA data\n",
    "# for num, pca in enumerate(numericalPCA.components_, 1):\n",
    "#     s = ''\n",
    "#     for index, title in enumerate(columnTitles):\n",
    "#         s += f\"{title}: { str(round(pca[index], 4))} | \"\n",
    "#     print(f\"PCA{num}: \\n{s}\")\n",
    "\n",
    "\n",
    "#cumulative explained variance\n",
    "ratioSum = numericalPCA.explained_variance_ratio_.cumsum()\n",
    "print('\\ncumulative sum:')\n",
    "print(ratioSum)\n",
    "\n",
    "plt.bar(range(1,len(ratioSum)+1), numericalPCA.explained_variance_ratio_, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(1,len(ratioSum)+1), ratioSum, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.ylim (0,1.05)\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get at 80% data capture, we would need at least six principle components. Five was slightly short by sitting at at value of 79.05% coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) 20 points (EP)\n",
    "Construct a biplot that displays the data points and the loadings of each original feature in the PC1-PC2 space. Label the loading vectors (arrows). Share your observations. Discuss which type of patient is best represented in each quadrant of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalTransformed = numericalPCA.fit_transform(numericalRescale)\n",
    "loadings = numericalPCA.components_\n",
    "\n",
    "# alter plot size so that legend will not overlap with datapoints\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.scatter(numericalTransformed[:,0], numericalTransformed[:,1], color='k')\n",
    "\n",
    "scalingFactor = 5.5\n",
    "\n",
    "columnTitles = numerical.columns.tolist()\n",
    "\n",
    "for i in range(loadings.shape[1]):\n",
    "    arrowColor = plt.cm.tab10(i / loadings.shape[1])\n",
    "    plt.arrow(0, 0, scalingFactor*loadings[0, i], scalingFactor*loadings[i, i],  color=arrowColor, linewidth=2, head_width=.2, head_length=.2, label=columnTitles[i])\n",
    "    \n",
    "plt.axis('equal');\n",
    "plt.xlabel(\"PCA1\")\n",
    "plt.ylabel(\"PCA2\")\n",
    "\n",
    "# create legend\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.title(\"Loadings of Original Features on PC1 and PC2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) 15 points (BH)\n",
    "Color-code the data points based on DEATH_EVENT or other categorical variables within the dataset. Evaluate whether dimension reduction has facilitated a clearer distinction between the various patient groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3- Clustering (100 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) 15 points (BH)\n",
    "Apply K-means clustering to the PCA-transformed data (referencing the number of PCA components selected in 2a). Experiment with a variety of K values and graph the resulting Inertias and Average Silhouette Coefficients for each K. Analyze the graphs to determine the optimal number of clusters. Which cluster count do you prefer when considering both metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================================\n",
    "#                           KMeans Clustering\n",
    "#==============================================================================================\n",
    "\n",
    "# 'pcaTransformedDataset' is the pca-transformed numpy array\n",
    "n_loops = 30 # consistent int to have the inertia and silhouette graph loop the same amount\n",
    "inertias = np.zeros(n_loops)\n",
    "#retrieves interias and fills them in empty array\n",
    "for i in range(1, n_loops+1):\n",
    "    kmeans = KMeans(n_clusters = i, init='k-means++', max_iter=300, random_state=0)\n",
    "    kmeans.fit_predict(pcaTransformedDataset)\n",
    "    inertias[i-1] = kmeans.inertia_\n",
    "#plots inertia\n",
    "plt.plot(range(1,n_loops+1), inertias, c='b', marker='.')\n",
    "plt.title(\"Inertia vs Number of Clusters\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()\n",
    "\n",
    "#==============================================================================================\n",
    "#                     Average Silhouette scores\n",
    "#==============================================================================================\n",
    "\n",
    "S_scores = []\n",
    "for n_clusters in range(2, n_loops+1):\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    \n",
    "    # Predict the cluster for each data point\n",
    "    preds = km.fit_predict(pcaTransformedDataset)\n",
    "\n",
    "    # Calculate the mean silhouette coefficient for the number of clusters chosen\n",
    "    score = silhouette_score(pcaTransformedDataset, preds, metric='euclidean')\n",
    "    S_scores.append(score)\n",
    "\n",
    "plt.plot(range(2,n_loops+1), S_scores, c='b', marker='.')\n",
    "plt.title(\" Average silhouette_score vs Number of Clusters\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Average silhouette_score\")\n",
    "plt.grid(\"y-axis\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering the inertia graph and the average silhouette graph, the optimal number of clusters appears to be 10. 10 is at the lower end of the interia 'elbow' as well as being the peak average silhouette score when testing 30 cluster sizes. Since this is most likely a local minimum, the graph shifts each time the program is run. After running it a handful of times, 10 has peaked the most on the average silhouette score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) 20 points (BH)\n",
    "Interpret the characteristics of typical patients in each cluster for the chosen K value from the previous question. This involves reversing the PCA and standard scaler transformations applied to the centroid vectors. Share your insights on the findings. Are there any notable differences between the clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverses pca\n",
    "originalNumData = numericalPCA.inverse_transform(pcaTransformedDataset)\n",
    "# reverses Standard Scaler\n",
    "originalNumData = scaler.inverse_transform(originalNumData)\n",
    "\n",
    "#\n",
    "kmeans = KMeans(n_clusters=10, init='k-means++', max_iter=300) #kmeans requires knowing the number of clusters. In this case we wouldnt know there are 4 so we assume 3\n",
    "pred_cluster_labels = kmeans.fit_predict(originalNumData) #array that tells you which point exists in which cluster\n",
    "\n",
    "plt.scatter(originalNumData[:,2],originalNumData[:,5], c=pred_cluster_labels)\n",
    "#plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], c='red', s=50)\n",
    "plt.xlabel(\"Ejectional Fraction\")\n",
    "plt.ylabel(\"Serum Sodium\")\n",
    "plt.title(\"Numerical Heart Failure K-Means Clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the clusters do not appear to have any correlation.The graph above is a visualization of the variables that had the most correlation: ejectional fraction and serum sodium. Even with this graph, each cluster appears to be randomly dispersed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) 20 points (BH)\n",
    "Using only the first two principal components (PCs), generate two scatterplot subplots. In the first subplot, color-code the data points according to the predicted cluster assignments. In the second subplot, use color-coding to represent 'death' or other categorical variables. Examine both plots and share any significant findings or patterns that become apparent from this comparative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartPCA = PCA(n_components=2) # two Principle Components\n",
    "heart_transformed = heartPCA.fit_transform(heart)\n",
    "kmeans = KMeans(n_clusters=10, init='k-means++') #kmeans requires knowing the number of clusters. In this case we wouldnt know there are 4 so we assume 3\n",
    "pred_cluster_labels = kmeans.fit_predict(originalNumData)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize =(10,5) )\n",
    "#left plot\n",
    "s1 = axes[0].scatter(heart_transformed[:,0], heart_transformed[:,1], c=pred_cluster_labels, alpha=.6)\n",
    "axes[0].set_xlabel(\"PCA1\")\n",
    "axes[0].set_ylabel(\"PCA2\")\n",
    "axes[0].set_title(\"PCA1 and PCA2 colored by cluster group\")\n",
    "\n",
    "#right plot\n",
    "s2 = axes[1].scatter(heart_transformed[:,0], heart_transformed[:,1], c=heart['DEATH_EVENT'], alpha=.6)\n",
    "axes[1].set_xlabel(\"PCA1\")\n",
    "axes[1].set_ylabel(\"PCA2\")\n",
    "axes[1].set_title(\"PCA1 and PCA2 compared to DEATH_EVENT\")\n",
    "\n",
    "#legends\n",
    "deathLabel = ['Alive', 'Dead']\n",
    "clusterLabel = [i for i in range(1,13)]\n",
    "axes[0].legend(handles=s1.legend_elements()[0], labels=clusterLabel, loc='upper right')\n",
    "axes[1].legend(handles=s2.legend_elements()[0], labels=deathLabel, loc='upper right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In problem 3b, we were generating clusters against the original numerical datapoints. When we graphed those, cluster points appeared to bea randomly spread out for eaceh graph. Howver, once you graph the PCAs as a whole, there is a clear distinction between each cluster. By only analyzing correlation between individual variables, we would never be able to identify these groups. The death_event graph is more spread out than I expected. There are more living outliers when looking towards the high-end of the first principle component. The inverse is true for the second principle component, the outliers are deceased toward the higher end. In terms of the average, death is consistent between all varialbes since the the majority of the PCA data is centered around the intersection between zero PCA 1 and zero PCA 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) 15 points (EP)\n",
    "\n",
    "Construct dendrograms for various linkage methods (complete, single, ward). Assess which linkage method appears most suitable. Determine the most appropriate number of clusters based on the dendrograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) 15 points (EP)\n",
    "Redo part a of problem 3, but use hierarchical clustering (AgglomerativeClustering) in place of k-means. Use the the linkage type you chose in previous question. Test different numbers of clusters and plot the resulting Inertias and Average Silhouette Coefficients for each cluster count. Examine these plots to identify the ideal number of clusters. Based on both metrics, which number of clusters seems most appropriate? Compare the results with those obtained from part a; did the choice of clustering method lead to a different outcome? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) 15 points (EP)\n",
    "Redo part c and compare the results. Any significant difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
